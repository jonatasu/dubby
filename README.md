# dubby

![CI](https://github.com/jonatasu/dubby/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/python-3.12%2B-blue)
![Docker](https://img.shields.io/badge/docker-ready-green)

**Tradu√ß√£o e dublagem de v√≠deos/√°udios com web UI moderna**

Pipeline completo: extra√ß√£o de √°udio ‚Üí transcri√ß√£o (ASR) ‚Üí tradu√ß√£o ‚Üí s√≠ntese de voz ‚Üí remux

‚úÖ **Funcionalidades ativas:**

- üé§ ASR com Faster-Whisper (modelo local)
- üåê Tradu√ß√£o com argostranslate (EN‚ÜîPT, EN‚ÜîES)
- üîä TTS com vozes nativas por idioma (pyttsx3)
- üé¨ Processamento de v√≠deo com FFmpeg
- üê≥ Deploy com Docker completo
- üöÄ Instala√ß√£o autom√°tica com bootstrap

## üöÄ Instala√ß√£o R√°pida (Recomendado)

### Op√ß√£o 1: Bootstrap Autom√°tico

```bash
# Clone o reposit√≥rio
git clone https://github.com/jonatasu/dubby.git
cd dubby

# Execute o bootstrap (instala tudo automaticamente)
python3 scripts/bootstrap.py
```

O script bootstrap:

- ‚úÖ Verifica Python 3.12+
- ‚úÖ Instala depend√™ncias do sistema
- ‚úÖ Cria ambiente virtual
- ‚úÖ Instala depend√™ncias Python
- ‚úÖ Baixa modelo ASR
- ‚úÖ Inicializa tradu√ß√£o
- ‚úÖ Testa funcionalidade

### Op√ß√£o 2: Docker (Zero Setup)

```bash
# Pull da imagem oficial
docker pull ghcr.io/jonatasu/dubby:latest

# Execute com volumes persistentes
docker run --rm -it -p 8000:8000 \
  -v "$PWD/models:/app/models" \
  -v "$PWD/uploads:/app/uploads" \
  -v "$PWD/outputs:/app/outputs" \
  ghcr.io/jonatasu/dubby:latest
```

## üìã Requisitos do Sistema

### Depend√™ncias Obrigat√≥rias

**Python 3.12+** (vers√£o est√°vel mais recente)

**Sistema (macOS):**

```bash
brew install ffmpeg git python@3.12
```

**Sistema (Ubuntu/Debian):**

```bash
sudo apt-get update
sudo apt-get install ffmpeg git python3.12 python3.12-venv espeak espeak-data
```

**Sistema (CentOS/RHEL):**

```bash
sudo yum install ffmpeg git python3.12 espeak
```

### Depend√™ncias Python (Autom√°ticas)

O arquivo `requirements.txt` inclui **todas as depend√™ncias com vers√µes fixas**:

```
# Core Framework
fastapi==0.115.0              # Web framework
uvicorn[standard]==0.30.6      # ASGI server
pydantic-settings==2.5.2      # Configuration

# Audio/Speech Processing
faster-whisper==1.0.3         # ASR
pyttsx3==2.99                  # TTS
scipy==1.14.0                  # Audio processing
soundfile==0.12.1              # Audio I/O
ffmpeg-python==0.2.0           # Video processing

# Translation (Fixed Versions)
argostranslate==1.9.6          # Translation engine
ctranslate2==4.6.0             # Translation backend
sacremoses==0.0.53             # Text preprocessing
sentencepiece==0.2.0           # Tokenization
stanza==1.1.1                  # NLP pipeline

# PyTorch Stack
torch==2.5.1                   # Deep learning
torchvision==0.20.1            # Vision utilities
torchaudio==2.5.1              # Audio utilities

# Testing
pytest==8.3.2                  # Testing framework
```

## üèÉ‚Äç‚ôÇÔ∏è Executar Localmente

### M√©todo 1: Make (Recomendado)

```bash
# Instalar depend√™ncias e executar
make run

# Ou apenas executar (se j√° instalado)
source .venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### M√©todo 2: Tasks do VS Code

Se estiver usando VS Code, use as tasks configuradas:

- `Ctrl+Shift+P` ‚Üí "Tasks: Run Task" ‚Üí "Run dubby (uvicorn)"

### Acesso

üåê **Web Interface:** http://localhost:8000

## üê≥ Docker

### Local Build & Run

```bash
# Build da imagem
docker build -t dubby:local .

# Execute com volumes (dados persistentes)
docker run --rm -it -p 8000:8000 \
  -v "$PWD/models:/app/models" \
  -v "$PWD/uploads:/app/uploads" \
  -v "$PWD/outputs:/app/outputs" \
  dubby:local
```

### Docker Compose (Recomendado)

```bash
# Build e execute em uma linha
docker compose up --build

# Execute em background
docker compose up -d --build
```

### Imagem Oficial (GHCR)

**Imagens pr√©-constru√≠das** est√£o dispon√≠veis no GitHub Container Registry:

```bash
# √öltima vers√£o (main branch)
docker pull ghcr.io/jonatasu/dubby:latest

# Vers√£o espec√≠fica (release tags)
docker pull ghcr.io/jonatasu/dubby:v1.0.0

# Execute a imagem oficial
docker run --rm -it -p 8000:8000 \
  -v "$PWD/models:/app/models" \
  -v "$PWD/uploads:/app/uploads" \
  -v "$PWD/outputs:/app/outputs" \
  ghcr.io/jonatasu/dubby:latest
```

## ‚òÅÔ∏è Deploy em Produ√ß√£o

### Plataformas Suportadas

**Container-based (Recomendado):**

- üöÄ Railway
- üî∏ Render
- ‚úàÔ∏è Fly.io
- ‚òÅÔ∏è Google Cloud Run
- üî∑ Azure Container Instances
- üì¶ AWS ECS/Fargate

**Configura√ß√£o b√°sica:**

- üê≥ Use a imagem: `ghcr.io/jonatasu/dubby:latest`
- üîå Exponha a porta: `8000`
- üíæ Monte volumes persistentes para: `models/`, `uploads/`, `outputs/`
- ‚öôÔ∏è Vari√°veis de ambiente: veja `.env.example`

### PythonAnywhere (ASGI)

PythonAnywhere suporta aplica√ß√µes ASGI:

1. **Ambiente virtual:** Crie com Python 3.12+ e instale `requirements.txt`
2. **Configura√ß√£o ASGI:** Aponte para `asgi:application` (arquivo `asgi.py`)
3. **Arquivos est√°ticos:** Mapeie `/static` para `app/static` e `/outputs` para `outputs`
4. **FFmpeg:** Se n√£o dispon√≠vel, o app funcionar√° apenas com √°udio
5. **Modelo offline:** Execute `python scripts/bootstrap.py` para configura√ß√£o completa

## üß™ Desenvolvimento e Testes

### Executar Testes

```bash
# Todos os testes
make test

# Com coverage
pytest --cov=app tests/

# Testes espec√≠ficos
pytest tests/test_health.py -v
```

### Estrutura de Testes

```
tests/
‚îú‚îÄ‚îÄ test_health.py          # Testes de endpoints
‚îú‚îÄ‚îÄ test_basic.py           # Testes de UI
‚îî‚îÄ‚îÄ test_services.py        # Testes de servi√ßos (ASR, tradu√ß√£o, TTS)
```

### Linting e Formata√ß√£o

```bash
# Ruff (linter)
ruff check .

# Black (formata√ß√£o)
black .

# Type checking
mypy app/
```

## üîß Troubleshooting

### Problemas Comuns

**1. Erro de importa√ß√£o argostranslate**

```bash
# Reinstale com vers√µes fixas
pip install -r requirements.txt --force-reinstall
```

**2. Modelo ASR n√£o encontrado**

```bash
# Re-baixe o modelo
python scripts/download_whisper_model.py
```

**3. TTS n√£o funciona (macOS)**

```bash
# Verifique se o sistema tem vozes instaladas
say "test" # Deve funcionar
```

**4. FFmpeg n√£o encontrado**

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Verifique instala√ß√£o
ffmpeg -version
```

**5. Problemas de permiss√£o (Docker)**

```bash
# Execute com usu√°rio atual
docker run --user $(id -u):$(id -g) ...
```

### Logs e Debug

```bash
# Logs detalhados
export DEBUG=1
uvicorn app.main:app --log-level debug

# Logs Docker
docker logs container_name

# Health check
curl http://localhost:8000/health
```

## üìä Status do Projeto

### ‚úÖ Funcionalidades Implementadas

- [x] **ASR (Automatic Speech Recognition)**
  - Faster-Whisper com modelo local
  - Suporte a m√∫ltiplos idiomas
  - Detec√ß√£o autom√°tica de idioma
- [x] **Tradu√ß√£o**
  - argostranslate offline
  - Pares: EN‚ÜîPT, EN‚ÜîES (expans√≠vel)
  - Instala√ß√£o autom√°tica de modelos
- [x] **TTS (Text-to-Speech)**
  - pyttsx3 com vozes nativas
  - Vozes espec√≠ficas por idioma
  - Configura√ß√£o autom√°tica de qualidade
- [x] **Processamento de M√≠dia**
  - FFmpeg para v√≠deo/√°udio
  - Extra√ß√£o e remux autom√°tico
  - Suporte a m√∫ltiplos formatos
- [x] **Web Interface**
  - Upload de arquivos
  - Sele√ß√£o de idiomas
  - Download de resultados
  - Status em tempo real
- [x] **Deploy e CI/CD**
  - Docker completo
  - GitHub Actions
  - GHCR publishing
  - Health checks

### üî¨ Experimental: Voice Cloning (OpenVoice & Spectral)

Status geral: camada de clonagem experimental suporta dois caminhos:

1. `openvoice` (ainda placeholder ‚Äì aguarda modelos reais)
2. `spectral` (Fase 1) pseudo-clone: ajusta pitch e brilho espectral do √°udio TTS gerado com base em um perfil da voz original.

#### Pipeline Alvo (OpenVoice completo)
1. Extrair √°udio original (refer√™ncia)
2. Gerar embedding / ‚Äútone color‚Äù
3. Converter texto traduzido em mel + vocoder com timbre preservado
4. Ajustar dura√ß√£o para casar com timestamps ASR

#### Modo Spectral (implementado nesta fase)
O modo `spectral` cria um perfil simples da voz de refer√™ncia:
- `pitch` (estimativa fundamental via autocorrela√ß√£o simplificada)
- `energy` (RMS)
- `centroid` (centro espectral)

Em seguida aplica sobre o √°udio TTS base:
- Pitch shift leve (misturado pela intensidade `voice_clone_pitch_strength`)
- Filtro de modelagem espectral (ajuste de brilho/formant simplificado ‚Äì intensidade `voice_clone_formant_strength`)

Objetivo: aproximar o timbre/altura original sem depend√™ncias pesadas enquanto a clonagem neural real n√£o chega.

#### Configura√ß√£o (vari√°veis / .env)
| Chave (.env / Settings) | Descri√ß√£o | Valores / Exemplo | Default |
|-------------------------|-----------|-------------------|---------|
| `VOICE_CLONE_ENABLED` | Liga/desliga qualquer tentativa de clonagem | true / false | true |
| `VOICE_CLONE_MODE` (`voice_clone_mode`) | Estrat√©gia | baseline | baseline |
|  |  | spectral (pseudo timbre) |  |
|  |  | openvoice (quando modelos prontos) |  |
| `VOICE_CLONE_PITCH_STRENGTH` (`voice_clone_pitch_strength`) | 0‚Äì1 intensidade do ajuste de pitch | 0.0‚Äì1.0 | 0.7 |
| `VOICE_CLONE_FORMANT_STRENGTH` (`voice_clone_formant_strength`) | 0‚Äì1 intensidade de brilho/formant | 0.0‚Äì1.0 | 0.5 |
| `OPENVOICE_MODELS_DIR` | Pasta de modelos OpenVoice | caminho | models/openvoice |
| `OPENVOICE_CLI_COMMAND` | Nome do bin√°rio CLI | openvoice | openvoice |

Exemplo `.env` para modo spectral:
```
VOICE_CLONE_ENABLED=true
VOICE_CLONE_MODE=spectral
VOICE_CLONE_PITCH_STRENGTH=0.6
VOICE_CLONE_FORMANT_STRENGTH=0.4
```

#### Instala√ß√£o de modelos OpenVoice (quando usar o modo openvoice)
```
python scripts/download_openvoice_models.py
```
Se bloqueado (proxy/SSL), baixe os arquivos `.pt` manualmente e coloque em `models/openvoice`.

#### Fallback & Seguran√ßa
- Aus√™ncia de modelos/CLI ou erros ‚Üí fallback autom√°tico para TTS nativo
- Erros n√£o interrompem pipeline de dublagem

#### Limita√ß√µes Atuais
- Modo spectral N√ÉO preserva exatamente voz (apenas heur√≠stica de pitch + brilho)
- Sem alinhamento fon√©tico ou pros√≥dia neural
- OpenVoice ainda n√£o gera √°udio real (placeholder)

#### Roadmap Pr√≥ximo
- [ ] Substituir placeholder OpenVoice por pipeline real (encoder + tone color + vocoder)
- [ ] Cache de embeddings / perfis
- [ ] Ajuste din√¢mico de dura√ß√£o por segmento (DTW / time-stretch controlado)
- [ ] Par√¢metros avan√ßados (pitch target override, preserva√ß√£o de energia)

### ÔøΩüîÆ Roadmap Futuro

- [ ] **Voice Cloning** (OpenVoice, RVC, Coqui TTS)
- [ ] **Tradu√ß√£o melhorada** (Google Translate API, Azure)
- [ ] **Streaming processing** (chunks em tempo real)
- [ ] **Multi-language UI** (i18n)
- [ ] **API keys management** (servi√ßos externos)
- [ ] **Batch processing** (m√∫ltiplos arquivos)

## üìù Licen√ßa

Este projeto est√° licenciado sob a [MIT License](LICENSE).

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/amazing-feature`
3. Commit suas mudan√ßas: `git commit -m 'Add amazing feature'`
4. Push para a branch: `git push origin feature/amazing-feature`
5. Abra um Pull Request

### Desenvolvimento Local

```bash
# Setup completo
python scripts/bootstrap.py

# Executar com reload
make run

# Testes antes do commit
make test
```

---

**‚ú® Dubby** - Powered by FastAPI, Faster-Whisper, argostranslate, and pyttsx3

## Uso

1. Acesse a p√°gina inicial e envie um arquivo de v√≠deo/√°udio.
2. Escolha idioma de entrada e sa√≠da.
3. Aguarde o processamento; baixe o resultado.

## Notas t√©cnicas

- ASR: `faster-whisper` (baixa modelos em `models/`).
- Tradu√ß√£o: `argostranslate` (instala pacotes sob demanda; veja `scripts/bootstrap_models.py`).
- TTS: `app/services/tts.py` implementa fallback (tom senoidal ajustado por segmento). Substitua por OpenVoice/servi√ßo para voz real.
- M√≠dia: `ffmpeg` para extra√ß√£o/mux.

### Ambientes com proxy/SSL corporativo (erro de certificado Hugging Face)

Se voc√™ ver erros como `SSLCertVerificationError` ou "download online est√° bloqueado" ao baixar modelos do Hugging Face:

- Op√ß√£o A (recomendada): operar com modelo local.
  1.  Baixe manualmente o reposit√≥rio do modelo (ex.: Systran/faster-whisper-medium) no diret√≥rio `models/`.
  2.  Defina `ASR_MODEL` no `.env` para o caminho local, por exemplo:
      `ASR_MODEL=models/Systran__faster-whisper-medium`
- Op√ß√£o B: configurar certificados/proxy do ambiente:
  - Defina vari√°veis `HTTPS_PROXY`/`HTTP_PROXY`.
  - Aponte `REQUESTS_CA_BUNDLE` e/ou `CURL_CA_BUNDLE` para o seu CA corporativo.
  - Reinicie o servidor ap√≥s ajustar o ambiente.

## Roadmap

- [ ] Clonagem de voz zero-shot (OpenVoice) com suporte multi-idiomas.
- [ ] Alinhamento de fala mais preciso (WhisperX/Aeneas).
- [ ] Fila de jobs e background workers.
- [ ] Melhorar UI e progresso.

## Aviso legal

Garanta que voc√™ tem direitos para transcrever, traduzir e clonar a voz do conte√∫do processado.

# dubby

![CI](https://github.com/jonatasu/dubby/actions/workflows/ci.yml/badge.svg)
![Python](https://img.shields.io/badge/python-3.12%2B-blue)
![Docker](https://img.shields.io/badge/docker-ready-green)

**TraduÃ§Ã£o e dublagem de vÃ­deos/Ã¡udios com web UI moderna**

Pipeline completo: extraÃ§Ã£o de Ã¡udio â†’ transcriÃ§Ã£o (ASR) â†’ traduÃ§Ã£o â†’ sÃ­ntese de voz â†’ remux

âœ… **Funcionalidades ativas:**

- ğŸ¤ ASR com Faster-Whisper (modelo local)
- ğŸŒ TraduÃ§Ã£o com argostranslate (ENâ†”PT, ENâ†”ES)
- ğŸ”Š TTS com vozes nativas por idioma (pyttsx3)
- ğŸ¬ Processamento de vÃ­deo com FFmpeg
- ğŸ³ Deploy com Docker completo
- ğŸš€ InstalaÃ§Ã£o automÃ¡tica com bootstrap

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida (Recomendado)

### OpÃ§Ã£o 1: Bootstrap AutomÃ¡tico

```bash
# Clone o repositÃ³rio
git clone https://github.com/jonatasu/dubby.git
cd dubby

# Execute o bootstrap (instala tudo automaticamente)
python3 scripts/bootstrap.py
```

O script bootstrap:

- âœ… Verifica Python 3.12+
- âœ… Instala dependÃªncias do sistema
- âœ… Cria ambiente virtual
- âœ… Instala dependÃªncias Python
- âœ… Baixa modelo ASR
- âœ… Inicializa traduÃ§Ã£o
- âœ… Testa funcionalidade

### OpÃ§Ã£o 2: Docker (Zero Setup)

```bash
# Pull da imagem oficial
docker pull ghcr.io/jonatasu/dubby:latest

# Execute com volumes persistentes
docker run --rm -it -p 8000:8000 \
  -v "$PWD/models:/app/models" \
  -v "$PWD/uploads:/app/uploads" \
  -v "$PWD/outputs:/app/outputs" \
  ghcr.io/jonatasu/dubby:latest
```

## ğŸ“‹ Requisitos do Sistema

### DependÃªncias ObrigatÃ³rias

**Python 3.12+** (versÃ£o estÃ¡vel mais recente)

**Sistema (macOS):**

```bash
brew install ffmpeg git python@3.12
```

**Sistema (Ubuntu/Debian):**

```bash
sudo apt-get update
sudo apt-get install ffmpeg git python3.12 python3.12-venv espeak espeak-data
```

**Sistema (CentOS/RHEL):**

```bash
sudo yum install ffmpeg git python3.12 espeak
```

### DependÃªncias Python (AutomÃ¡ticas)

O arquivo `requirements.txt` inclui **todas as dependÃªncias com versÃµes fixas**:

```
# Core Framework
fastapi==0.115.0              # Web framework
uvicorn[standard]==0.30.6      # ASGI server
pydantic-settings==2.5.2      # Configuration

# Audio/Speech Processing
faster-whisper==1.0.3         # ASR
pyttsx3==2.99                  # TTS
scipy==1.14.0                  # Audio processing
soundfile==0.12.1              # Audio I/O
ffmpeg-python==0.2.0           # Video processing

# Translation (Fixed Versions)
argostranslate==1.9.6          # Translation engine
ctranslate2==4.6.0             # Translation backend
sacremoses==0.0.53             # Text preprocessing
sentencepiece==0.2.0           # Tokenization
stanza==1.1.1                  # NLP pipeline

# PyTorch Stack
torch==2.5.1                   # Deep learning
torchvision==0.20.1            # Vision utilities
torchaudio==2.5.1              # Audio utilities

# Testing
pytest==8.3.2                  # Testing framework
```

## ğŸƒâ€â™‚ï¸ Executar Localmente

### MÃ©todo 1: Make (Recomendado)

```bash
# Instalar dependÃªncias e executar
make run

# Ou apenas executar (se jÃ¡ instalado)
source .venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

### MÃ©todo 2: Tasks do VS Code

Se estiver usando VS Code, use as tasks configuradas:

- `Ctrl+Shift+P` â†’ "Tasks: Run Task" â†’ "Run dubby (uvicorn)"

### Acesso

ğŸŒ **Web Interface:** http://localhost:8000

## ğŸ³ Docker

### Local Build & Run

```bash
# Build da imagem
docker build -t dubby:local .

# Execute com volumes (dados persistentes)
docker run --rm -it -p 8000:8000 \
  -v "$PWD/models:/app/models" \
  -v "$PWD/uploads:/app/uploads" \
  -v "$PWD/outputs:/app/outputs" \
  dubby:local
```

### Docker Compose (Recomendado)

```bash
# Build e execute em uma linha
docker compose up --build

# Execute em background
docker compose up -d --build
```

### Imagem Oficial (GHCR)

**Imagens prÃ©-construÃ­das** estÃ£o disponÃ­veis no GitHub Container Registry:

```bash
# Ãšltima versÃ£o (main branch)
docker pull ghcr.io/jonatasu/dubby:latest

# VersÃ£o especÃ­fica (release tags)
docker pull ghcr.io/jonatasu/dubby:v1.0.0

# Execute a imagem oficial
docker run --rm -it -p 8000:8000 \
  -v "$PWD/models:/app/models" \
  -v "$PWD/uploads:/app/uploads" \
  -v "$PWD/outputs:/app/outputs" \
  ghcr.io/jonatasu/dubby:latest
```

## â˜ï¸ Deploy em ProduÃ§Ã£o

### Plataformas Suportadas

**Container-based (Recomendado):**

- ğŸš€ Railway
- ğŸ”¸ Render
- âœˆï¸ Fly.io
- â˜ï¸ Google Cloud Run
- ğŸ”· Azure Container Instances
- ğŸ“¦ AWS ECS/Fargate

**ConfiguraÃ§Ã£o bÃ¡sica:**

- ğŸ³ Use a imagem: `ghcr.io/jonatasu/dubby:latest`
- ğŸ”Œ Exponha a porta: `8000`
- ğŸ’¾ Monte volumes persistentes para: `models/`, `uploads/`, `outputs/`
- âš™ï¸ VariÃ¡veis de ambiente: veja `.env.example`

### PythonAnywhere (ASGI)

PythonAnywhere suporta aplicaÃ§Ãµes ASGI:

1. **Ambiente virtual:** Crie com Python 3.12+ e instale `requirements.txt`
2. **ConfiguraÃ§Ã£o ASGI:** Aponte para `asgi:application` (arquivo `asgi.py`)
3. **Arquivos estÃ¡ticos:** Mapeie `/static` para `app/static` e `/outputs` para `outputs`
4. **FFmpeg:** Se nÃ£o disponÃ­vel, o app funcionarÃ¡ apenas com Ã¡udio
5. **Modelo offline:** Execute `python scripts/bootstrap.py` para configuraÃ§Ã£o completa

## ğŸ§ª Desenvolvimento e Testes

### Executar Testes

```bash
# Todos os testes
make test

# Com coverage
pytest --cov=app tests/

# Testes especÃ­ficos
pytest tests/test_health.py -v
```

### Estrutura de Testes

```
tests/
â”œâ”€â”€ test_health.py          # Testes de endpoints
â”œâ”€â”€ test_basic.py           # Testes de UI
â””â”€â”€ test_services.py        # Testes de serviÃ§os (ASR, traduÃ§Ã£o, TTS)
```

### Linting e FormataÃ§Ã£o

```bash
# Ruff (linter)
ruff check .

# Black (formataÃ§Ã£o)
black .

# Type checking
mypy app/
```

## ğŸ”§ Troubleshooting

### Problemas Comuns

**1. Erro de importaÃ§Ã£o argostranslate**

```bash
# Reinstale com versÃµes fixas
pip install -r requirements.txt --force-reinstall
```

**2. Modelo ASR nÃ£o encontrado**

```bash
# Re-baixe o modelo
python scripts/download_whisper_model.py
```

**3. TTS nÃ£o funciona (macOS)**

```bash
# Verifique se o sistema tem vozes instaladas
say "test" # Deve funcionar
```

**4. FFmpeg nÃ£o encontrado**

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt-get install ffmpeg

# Verifique instalaÃ§Ã£o
ffmpeg -version
```

**5. Problemas de permissÃ£o (Docker)**

```bash
# Execute com usuÃ¡rio atual
docker run --user $(id -u):$(id -g) ...
```

### Logs e Debug

```bash
# Logs detalhados
export DEBUG=1
uvicorn app.main:app --log-level debug

# Logs Docker
docker logs container_name

# Health check
curl http://localhost:8000/health
```

## ğŸ“Š Status do Projeto

### âœ… Funcionalidades Implementadas

- [x] **ASR (Automatic Speech Recognition)**
  - Faster-Whisper com modelo local
  - Suporte a mÃºltiplos idiomas
  - DetecÃ§Ã£o automÃ¡tica de idioma
- [x] **TraduÃ§Ã£o**
  - argostranslate offline
  - Pares: ENâ†”PT, ENâ†”ES (expansÃ­vel)
  - InstalaÃ§Ã£o automÃ¡tica de modelos
- [x] **TTS (Text-to-Speech)**
  - pyttsx3 com vozes nativas
  - Vozes especÃ­ficas por idioma
  - ConfiguraÃ§Ã£o automÃ¡tica de qualidade
- [x] **Processamento de MÃ­dia**
  - FFmpeg para vÃ­deo/Ã¡udio
  - ExtraÃ§Ã£o e remux automÃ¡tico
  - Suporte a mÃºltiplos formatos
- [x] **Web Interface**
  - Upload de arquivos
  - SeleÃ§Ã£o de idiomas
  - Download de resultados
  - Status em tempo real
- [x] **Deploy e CI/CD**
  - Docker completo
  - GitHub Actions
  - GHCR publishing
  - Health checks

### ğŸ”¬ Experimental: Voice Cloning (OpenVoice & Spectral)

Status geral: camada de clonagem experimental suporta dois caminhos:

1. `openvoice` (ainda placeholder â€“ aguarda modelos reais)
2. `spectral` (Fase 1) pseudo-clone: ajusta pitch e brilho espectral do Ã¡udio TTS gerado com base em um perfil da voz original.

#### Pipeline Alvo (OpenVoice completo)

1. Extrair Ã¡udio original (referÃªncia)
2. Gerar embedding / â€œtone colorâ€
3. Converter texto traduzido em mel + vocoder com timbre preservado
4. Ajustar duraÃ§Ã£o para casar com timestamps ASR

#### Modo Spectral (implementado nesta fase)

O modo `spectral` cria um perfil simples da voz de referÃªncia:

- `pitch` (estimativa fundamental via autocorrelaÃ§Ã£o simplificada)
- `energy` (RMS)
- `centroid` (centro espectral)

Em seguida aplica sobre o Ã¡udio TTS base:

- Pitch shift leve (misturado pela intensidade `voice_clone_pitch_strength`)
- Filtro de modelagem espectral (ajuste de brilho/formant simplificado â€“ intensidade `voice_clone_formant_strength`)

Objetivo: aproximar o timbre/altura original sem dependÃªncias pesadas enquanto a clonagem neural real nÃ£o chega.

#### ConfiguraÃ§Ã£o (variÃ¡veis / .env)

| Chave (.env / Settings)                                         | DescriÃ§Ã£o                                   | Valores / Exemplo                  | Default          |
| --------------------------------------------------------------- | ------------------------------------------- | ---------------------------------- | ---------------- |
| `VOICE_CLONE_ENABLED`                                           | Liga/desliga qualquer tentativa de clonagem | true / false                       | true             |
| `VOICE_CLONE_MODE` (`voice_clone_mode`)                         | EstratÃ©gia                                  | baseline                           | baseline         |
|                                                                 |                                             | spectral (pseudo timbre)           |                  |
|                                                                 |                                             | openvoice (quando modelos prontos) |                  |
| `VOICE_CLONE_PITCH_STRENGTH` (`voice_clone_pitch_strength`)     | 0â€“1 intensidade do ajuste de pitch          | 0.0â€“1.0                            | 0.7              |
| `VOICE_CLONE_FORMANT_STRENGTH` (`voice_clone_formant_strength`) | 0â€“1 intensidade de brilho/formant           | 0.0â€“1.0                            | 0.5              |
| `OPENVOICE_MODELS_DIR`                                          | Pasta de modelos OpenVoice                  | caminho                            | models/openvoice |
| `OPENVOICE_CLI_COMMAND`                                         | Nome do binÃ¡rio CLI                         | openvoice                          | openvoice        |

Exemplo `.env` para modo spectral:

```
VOICE_CLONE_ENABLED=true
VOICE_CLONE_MODE=spectral
VOICE_CLONE_PITCH_STRENGTH=0.6
VOICE_CLONE_FORMANT_STRENGTH=0.4
```

#### InstalaÃ§Ã£o de modelos OpenVoice (quando usar o modo openvoice)

```
python scripts/download_openvoice_models.py
```

Se bloqueado (proxy/SSL), baixe os arquivos `.pt` manualmente e coloque em `models/openvoice`.

#### Fallback & SeguranÃ§a

- AusÃªncia de modelos/CLI ou erros â†’ fallback automÃ¡tico para TTS nativo
- Erros nÃ£o interrompem pipeline de dublagem

#### LimitaÃ§Ãµes Atuais

- Modo spectral NÃƒO preserva exatamente voz (apenas heurÃ­stica de pitch + brilho)
- Sem alinhamento fonÃ©tico ou prosÃ³dia neural
- OpenVoice ainda nÃ£o gera Ã¡udio real (placeholder)

âš  Python 3.13+: o pacote `openvoice-cli` (<=0.0.5) depende de componentes (`audioop`) removidos
na stdlib nesta versÃ£o. Por isso a detecÃ§Ã£o neural Ã© desabilitada automaticamente em Python 3.13+
e o sistema recai para `spectral` ou `baseline`. Para testar futura integraÃ§Ã£o neural, use Python 3.12
ou aguarde atualizaÃ§Ã£o upstream.

#### Roadmap PrÃ³ximo

- [ ] Substituir placeholder OpenVoice por pipeline real (encoder + tone color + vocoder)
- [ ] Cache de embeddings / perfis
- [ ] Ajuste dinÃ¢mico de duraÃ§Ã£o por segmento (DTW / time-stretch controlado)
- [ ] ParÃ¢metros avanÃ§ados (pitch target override, preservaÃ§Ã£o de energia)

### ï¿½ğŸ”® Roadmap Futuro

- [ ] **Voice Cloning** (OpenVoice, RVC, Coqui TTS)
- [ ] **TraduÃ§Ã£o melhorada** (Google Translate API, Azure)
- [ ] **Streaming processing** (chunks em tempo real)
- [ ] **Multi-language UI** (i18n)
- [ ] **API keys management** (serviÃ§os externos)
- [ ] **Batch processing** (mÃºltiplos arquivos)

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/amazing-feature`
3. Commit suas mudanÃ§as: `git commit -m 'Add amazing feature'`
4. Push para a branch: `git push origin feature/amazing-feature`
5. Abra um Pull Request

### Desenvolvimento Local

```bash
# Setup completo
python scripts/bootstrap.py

# Executar com reload
make run

# Testes antes do commit
make test
```

---

**âœ¨ Dubby** - Powered by FastAPI, Faster-Whisper, argostranslate, and pyttsx3

## Uso

1. Acesse a pÃ¡gina inicial e envie um arquivo de vÃ­deo/Ã¡udio.
2. Escolha idioma de entrada e saÃ­da.
3. Aguarde o processamento; baixe o resultado.

## Notas tÃ©cnicas

- ASR: `faster-whisper` (baixa modelos em `models/`).
- TraduÃ§Ã£o: `argostranslate` (instala pacotes sob demanda; veja `scripts/bootstrap_models.py`).
- TTS: `app/services/tts.py` implementa fallback (tom senoidal ajustado por segmento). Substitua por OpenVoice/serviÃ§o para voz real.
- MÃ­dia: `ffmpeg` para extraÃ§Ã£o/mux.

### Ambientes com proxy/SSL corporativo (erro de certificado Hugging Face)

Se vocÃª ver erros como `SSLCertVerificationError` ou "download online estÃ¡ bloqueado" ao baixar modelos do Hugging Face:

- OpÃ§Ã£o A (recomendada): operar com modelo local.
  1.  Baixe manualmente o repositÃ³rio do modelo (ex.: Systran/faster-whisper-medium) no diretÃ³rio `models/`.
  2.  Defina `ASR_MODEL` no `.env` para o caminho local, por exemplo:
      `ASR_MODEL=models/Systran__faster-whisper-medium`
- OpÃ§Ã£o B: configurar certificados/proxy do ambiente:
  - Defina variÃ¡veis `HTTPS_PROXY`/`HTTP_PROXY`.
  - Aponte `REQUESTS_CA_BUNDLE` e/ou `CURL_CA_BUNDLE` para o seu CA corporativo.
  - Reinicie o servidor apÃ³s ajustar o ambiente.

## Roadmap

- [ ] Clonagem de voz zero-shot (OpenVoice) com suporte multi-idiomas.
- [ ] Alinhamento de fala mais preciso (WhisperX/Aeneas).
- [ ] Fila de jobs e background workers.
- [ ] Melhorar UI e progresso.

## Aviso legal

Garanta que vocÃª tem direitos para transcrever, traduzir e clonar a voz do conteÃºdo processado.
